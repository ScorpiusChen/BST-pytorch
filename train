# BST-pytorch
BST-pttorch
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import gc

torch.cuda.empty_cache()
gc.collect()

# 设置环境变量以指定使用的 GPU
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# 设置设备
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
torch.cuda.empty_cache()


class CTRDataset(Dataset):
    def __init__(self, data_dir):
        self.data = []
        self.labels = []
        for label in ['0', '1']:
            folder = os.path.join(data_dir, label)
            for filename in os.listdir(folder):
                if filename.endswith('.pt'):
                    tensor = torch.load(os.path.join(folder, filename), map_location='cpu')  # 加载到CPU
                    if torch.isnan(tensor).any():
                        print(f'NaN values found in {filename}')
                    else:
                        self.data.append(tensor)
                        self.labels.append(int(label))
        print("Dataset initialization complete")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        tensor = self.data[idx].to(device)  # 在使用时将数据移到GPU
        label = self.labels[idx]
        return tensor, label


class GlobalAttention(nn.Module):
    def __init__(self, d_model):
        super(GlobalAttention, self).__init__()
        self.query = nn.Linear(d_model, d_model)
        self.key = nn.Linear(d_model, d_model)
        self.value = nn.Linear(d_model, d_model)
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, x):
        query = self.query(x)
        key = self.key(x)
        value = self.value(x)
        attn_weights = torch.matmul(query, key.transpose(-2, -1))
        attn_weights = self.softmax(attn_weights)
        attn_output = torch.matmul(attn_weights, value)
        return attn_output


class TransformerBlock(nn.Module):
    def __init__(self, d_model, d_ff, dropout=0.1):
        super(TransformerBlock, self).__init__()
        self.attention = GlobalAttention(d_model)
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.ff = nn.Sequential(
            nn.Linear(d_model, d_ff),
            nn.ReLU(),
            nn.Linear(d_ff, d_model)
        )
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # 自注意力机制之后的残差连接和归一化
        attn_output = self.attention(x)
        x = x + self.dropout(attn_output)
        x = self.norm1(x)

        # 前馈网络之后的残差连接和归一化
        ff_output = self.ff(x)
        x = x + self.dropout(ff_output)
        x = self.norm2(x)

        return x


class Transformer(nn.Module):
    def __init__(self, d_model, d_ff, num_layers, dropout=0.1):
        super(Transformer, self).__init__()
        self.layers = nn.ModuleList([
            TransformerBlock(d_model, d_ff, dropout)
            for _ in range(num_layers)])
        self.fc_out = nn.Linear(d_model, d_model)

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return x


class CTRModel(nn.Module):
    def __init__(self):
        super(CTRModel, self).__init__()
        self.transformer = Transformer(d_model=513, d_ff=2048, num_layers=6)
        self.embedding = nn.Embedding(8, 8)  # 8个标签映射到8维嵌入
        self.linear = nn.Sequential(
            nn.Linear(513 * 21 + 8, 512),
            nn.LeakyReLU(),
            nn.Linear(512, 256),
            nn.LeakyReLU(),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
        # 定义one-hot编码到标签的映射
        self.label_mapping = {
        #  自定义
        }

    def forward(self, x):
        num_rows = x.size(1)
        row_features = x[:, :21, 1:]
        other_features = x[:, 21, :8]
        position_features = x[:, :21, 0].unsqueeze(-1)
        row_features = torch.cat((position_features, row_features), dim=-1)

        transformer_output = self.transformer(row_features.permute(1, 0, 2)).permute(1, 0, 2)
        transformer_output_flat = transformer_output.contiguous().view(transformer_output.size(0), -1)

        # # 不使用embedingg将transformer_output_flat和other_features_embedded连接起来
        final_input = torch.cat((transformer_output_flat, other_features), dim=1)
        # # 从one-hot编码解码other_features
        # other_features_indices = torch.argmax(other_features, dim=1)
        #
        # # 使用嵌入层将索引映射到8维向量
        # other_features_embedded = self.embedding(other_features_indices)
        #
        # # 将transformer_output_flat和other_features_embedded连接起来
        # final_input = torch.cat((transformer_output_flat, other_features_embedded), dim=1)

        output = self.linear(final_input)
        return output


def train_model(model, train_loader, optimizer, num_epochs=20, val_loader=None):
    print("Training started!")
    train_losses = []
    val_aucs = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for i, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = nn.BCELoss()(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if (i + 1) % 10 == 0:
                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')

        train_losses.append(running_loss / len(train_loader))

        if val_loader is not None:
            auc = evaluate_model(val_loader, model)
            val_aucs.append(auc)
            print(f'Epoch [{epoch + 1}/{num_epochs}], Validation AUC: {auc:.4f}')

    # 绘制训练损失和验证AUC曲线
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(val_aucs, label='Validation AUC')
    plt.xlabel('Epoch')
    plt.ylabel('AUC')
    plt.legend()
    plt.savefig("CTR_Model.png")
    plt.show()


def evaluate_model(val_loader, model):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)
            outputs = model(inputs)
            all_preds.append(outputs.cpu().numpy())
            all_labels.append(labels.cpu().numpy())
    all_preds = np.concatenate(all_preds)
    all_labels = np.concatenate(all_labels)
    auc = roc_auc_score(all_labels, all_preds)
    print(f'Validation AUC: {auc:.4f}')
    return auc


train_data_path = 'your'dataset'
val_data_path = 'yourdataset'

train_dataset = CTRDataset(train_data_path)
val_dataset = CTRDataset(val_data_path)

train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True, pin_memory=False, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False, pin_memory=False, num_workers=0)

model = CTRModel()

if torch.cuda.device_count() > 1:
    print(f'Using {torch.cuda.device_count()} GPUs!')
    model = nn.DataParallel(model)

model.to(device)
optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.001)

train_model(model, train_loader, optimizer, num_epochs=20, val_loader=val_loader)
evaluate_model(val_loader, model)
